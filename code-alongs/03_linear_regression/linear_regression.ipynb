{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35ea00b",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d525bedb",
   "metadata": {},
   "source": [
    "# Advertisement data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8661e4a4",
   "metadata": {},
   "source": [
    "## Short EDA on ads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ddb7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data into pandas dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"advertising.csv\", index_col=0)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# and start doing some EDA\n",
    "\n",
    "print(f\"{df.shape[0]} samples\")\n",
    "print(f\"{df.shape[1]-1} features\") # subtract one as price_unit_area is the label and not    \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e856b",
   "metadata": {},
   "source": [
    "-features/independent variable: TV, radio, newspaper\n",
    "\n",
    "-label/target/dependent variable: sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d0ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200 rows/samples\n",
    "# 4 column: 3 features and 1 label\n",
    "\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f90fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# 1 example plot\n",
    "\n",
    "sns.scatterplot(data = df, x=\"TV\", y=\"Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f66efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#want to plot TV, radio, news vs sales on the 3 axes\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(14,4))\n",
    "sns.scatterplot(data = df, x = \"TV\", y=\"Sales\", ax = axes[0])\n",
    "sns.scatterplot(data = df, x = \"Radio\", y=\"Sales\", ax = axes[1])\n",
    "sns.scatterplot(data = df, x = \"Newspaper\", y=\"Sales\", ax = axes[2])\n",
    "\n",
    "axes[0].set(title = \"TV spending vs sales\")\n",
    "\n",
    "#and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260c261",
   "metadata": {},
   "source": [
    "same as above, but put into loop to keep it more DRY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(14,4))\n",
    "\n",
    "features = (\"TV\",\"Radio\", \"Newspaper\")\n",
    "for feature, ax in zip(features, axes.flatten()):\n",
    "    sns.scatterplot(data = df, x = feature, y=\"Sales\", ax = ax)  \n",
    "    ax.set(title=f\"{feature} vs sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd1e41",
   "metadata": {},
   "source": [
    "## Scikit-learn steps\n",
    "\n",
    "See this as a recipe to follow, works for most machine learning algorithms with some modifications\n",
    "\n",
    "steps:\n",
    "\n",
    "0. divide into feature matrix X and label y\n",
    "1. train|test split\n",
    "2. scale dataset ( some algorithms don´t need scaling)\n",
    "3. fit algorithm with training data\n",
    "4. transform training data and test data\n",
    "5. evealuate on test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c920682",
   "metadata": {},
   "source": [
    "### 0. Divide into features X and labe y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5adfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Sales\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e6009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[[\"TV\", \"Newspaper\"\"Radio\"]]\n",
    "X = df.drop(\"Sales\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f73ae0",
   "metadata": {},
   "source": [
    "common way that i will do the above with tuple unpacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47497431",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y=  df.drop(\"Sales\", axis=1), df[\"Sales\"]\n",
    "\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b0c51",
   "metadata": {},
   "source": [
    "### 1. Train|test split\n",
    "\n",
    "- possible to do manually, but sklearn has this implemented of off the shelf that we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef26e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f\"{X_train.shape = }\")\n",
    "print(f\"{X_test.shape = }\")\n",
    "print(f\"{y_train.shape = }\")\n",
    "print(f\"{y_test.shape = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bbc21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327fa657",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302453f6",
   "metadata": {},
   "source": [
    "### 2. scale dataset\n",
    "\n",
    "common scaling techniques\n",
    "- min-max also called normalization\n",
    "- feature standardization\n",
    "\n",
    "many algorithms work better or only works when the features as scaled\n",
    "- values \"closer\" to each other\n",
    "\n",
    "for normalization\n",
    "-  $X' = \\frac{X-X_{min}}{X_{max}-X_{min}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f282181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# instantiate a MinMaxScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# important note: fit on X-train and not X_test -> this avoids data leakage\n",
    "scaler.fit(X_train) # use training data to fit the scaler\n",
    "\n",
    "# transforms or scales X_train and X_test\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "scaled_X_train.shape, scaled_X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train.min(), scaled_X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539da0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have used parameters X_min abd X_max from X_train to scale X_test\n",
    "# if you get exactly 0 and 1 here then probably you have fit X_test which would leak data\n",
    "scaled_X_test.min(), scaled_X_test.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf1f41",
   "metadata": {},
   "source": [
    "### 3. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb24ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "# put in training data features and label\n",
    "model.fit(scaled_X_train, y_train)\n",
    "\n",
    "model.intercept_, model.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d0b299",
   "metadata": {},
   "source": [
    "test manual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "122b15a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54988164, 0.63709677, 0.52286282])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TV, radio, news but scaled\n",
    "test_sample_feature = scaled_X_test[0]\n",
    "\n",
    "test_sample_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07f6cbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction on the test sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(16.586730852231778)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = model.coef_\n",
    "w0 = model.intercept_\n",
    "\n",
    "print(\"prediction on the test sample\")\n",
    "w0 + w[0]*test_sample_feature[0] + w[1]*test_sample_feature[1] +  w[2]*test_sample_feature[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec45659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for our test sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(16.9)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"label for our test sample\")\n",
    "y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd9b73",
   "metadata": {},
   "source": [
    "###  4. Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6308c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.58673085, 21.18622524, 21.66752973, 10.81086512, 22.25210881,\n",
       "       13.31459455, 21.23875284,  7.38400509, 13.43971113, 15.19445383,\n",
       "        9.01548612,  6.56945204, 14.4156926 ,  8.93560138,  9.56335776,\n",
       "       12.10760805,  8.86091137, 16.25163621, 10.31036304, 18.83571624,\n",
       "       19.81058732, 13.67550716, 12.45182294, 21.58072583,  7.67409148,\n",
       "        5.67090757, 20.95448184, 11.89301758,  9.13043149,  8.49435255,\n",
       "       12.32217788,  9.99097553, 21.71995241, 12.64869606, 18.25348116,\n",
       "       20.17390876, 14.20864218, 21.02816483, 10.91608737,  4.42671034,\n",
       "        9.59359543, 12.53133363, 10.14637196,  8.1294087 , 13.32973122,\n",
       "        5.27563699,  9.30534511, 14.15272317,  8.75979349, 11.67053724,\n",
       "       15.66273733, 11.75350353, 13.21744723, 11.06273296,  6.41769181,\n",
       "        9.84865789,  9.45756213, 24.32601732,  7.68903682, 12.30794356,\n",
       "       17.57952015, 15.27952025, 11.45659815, 11.12311877, 16.60003773,\n",
       "        6.90611478])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(scaled_X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da817c11",
   "metadata": {},
   "source": [
    "### Evaluate performance\n",
    "\n",
    "How well did we predict $\\bf{y}$ (label) with $\\hat{\\bf{y}}$ (y_pred)?\n",
    "\n",
    "To answer this question we use several **evaluation metrics** or **loss functions**: \n",
    "\n",
    "- Mean Absolute Error (MAE) - mean of error between $\\bf{y}$ and ${\\hat{\\bf{y}}}$. The unit is same as measured quantity.\n",
    "\n",
    "$$MAE = \\frac{1}{m}\\sum_{i=1}^m |y_i - \\hat{y}_i|$$\n",
    "\n",
    "- Mean Squared Error (MSE) - mean of squared errors between $\\bf{y}$ and ${\\hat{\\bf{y}}}$. It punishes large errors, and the units are in square units of the measured quantity\n",
    "\n",
    "$$MSE = \\frac{1}{m}\\sum_{i=1}^m (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "- Root Mean Squared Error (RMSE) - square root of MSE between $\\bf{y}$ and ${\\hat{\\bf{y}}}$. It punishes large errors, and the units are same as measured quantity, hence easier to interpret.\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{1}{m}\\sum_{i=1}^m (y_i - \\hat{y}_i)^2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52e3fdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4937750024728977, 3.72792833068152, np.float64(1.9307843822347228))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "mae, mse, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8c932",
   "metadata": {},
   "source": [
    "take the evalutation metrics and compare it to other models\n",
    "\n",
    "ex\n",
    "- linear regression gave us RMSE = 1.93\n",
    "- random forest gave us RMSE = 1.75\n",
    "\n",
    "-> choose random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77890d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a00e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7f589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c73219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a648fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de99f009",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3fb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15692ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0286a3ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "538c5a3d",
   "metadata": {},
   "source": [
    "Below is not in class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fef86b",
   "metadata": {},
   "source": [
    "Dependent and independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(\"Sales\", axis=\"columns\"), df[\"Sales\"]\n",
    "X.head(2), y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7077232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4a51cc",
   "metadata": {},
   "source": [
    "Train|test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7c4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d5ff4c",
   "metadata": {},
   "source": [
    "Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7630bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use normalization here\n",
    "# instantiate an object from the class MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train) # use the training data to fit the scaler\n",
    "\n",
    "# very important that we fit to training data, i.e. use training datas parameters to transform \n",
    "# both training and test data, else if we use test datas parameters to scale test data, we have \n",
    "# leaked data, which might give misleading results \n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"{scaled_X_train.min():.2f} ≤ scaled_X_train ≤ {scaled_X_train.max():.2f}\")\n",
    "print(f\"{scaled_X_test.min():.2f} ≤ scaled_X_test ≤ {scaled_X_test.max():.2f}\") # natural that it isn't [0,1] since we fit to training data \n",
    "\n",
    "# we do not scale our target variable y in this lecture "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e4c3e2",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# this model uses SVD approach for solving normal equation\n",
    "model = LinearRegression()\n",
    "model.fit(scaled_X_train, y_train)\n",
    "print(f\"Parameters: {model.coef_}\")\n",
    "print(f\"Intercept parameter: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d8409c",
   "metadata": {},
   "source": [
    "Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first predict on our test data\n",
    "y_pred = model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b8acd",
   "metadata": {},
   "source": [
    "Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aaa953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}, MSE: {mse:.2f}, RMSE: {rmse:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-sadia-awan-mlops25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
